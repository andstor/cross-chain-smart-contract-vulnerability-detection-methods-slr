\chapter{Research results}
\label{chap:results}
This chapter presents the results of this \acrfull{slr}. Firstly, a descriptive analysis of the selected literature is presented. Following are the results for each of the research questions defined in \cref{sec:research-questions}.

\section{Descriptive analysis}
This study analyzes a total of ?? research papers, published between 2018 and 2021. No publications earlier than 2018 were available. From then on, the number of publications has drastically increased. An distribution of selected literature type ordered by year is illustrated in \cref{fig:literature-types}. It shows an upwards trend in term of publications. It is also to be noted that the majority of the publications are conference proceedings. This is to be expected, as the field of smart contract security is a relative new field.

\newcounter{groupcount}
\pgfplotsset{
    draw group line/.style n args={5}{
        after end axis/.append code={
            \setcounter{groupcount}{0}
            \pgfplotstableforeachcolumnelement{#1}\of\datatable\as\cell{%
                \def\temp{#2}
                \ifx\temp\cell
                    \ifnum\thegroupcount=0
                        \stepcounter{groupcount}
                        \pgfplotstablegetelem{\pgfplotstablerow}{[index]0}\of\datatable
                        \coordinate [yshift=#4] (startgroup) at (axis cs:\pgfplotsretval,0);
                    \else
                        \pgfplotstablegetelem{\pgfplotstablerow}{[index]0}\of\datatable
                        \coordinate [yshift=#4] (endgroup) at (axis cs:\pgfplotsretval,0);
                    \fi
                \else
                    \ifnum\thegroupcount=1
                        \setcounter{groupcount}{0}
                        \draw [
                            shorten >=-#5,
                            shorten <=-#5
                        ] (startgroup) -- node [anchor=base, yshift=0.5ex] {#3} (endgroup);
                        %] (startgroup) -- node [anchor=north] {#3} (endgroup);
                    \fi
                \fi
            }
            \ifnum\thegroupcount=1
                        \setcounter{groupcount}{0}
                        \draw [
                            shorten >=-#5,
                            shorten <=-#5
                        ] (startgroup) -- node [anchor=base, yshift=0.5ex] {#3} (endgroup);
                        %] (startgroup) -- node [anchor=north] {#3} (endgroup);
            \fi
        }
    }
}

\begin{figure}[htp]
    \centering
    \begin{tikzpicture}
        \pgfplotstableread[col sep = comma]{data/publication-year-type.csv}\datatable
        \begin{axis}[
            width=\textwidth,
            height=8cm,
            ymin=0,
            %ymax=23,
            %ylabel={Percentagem},
            xtick=data,
            xticklabels from table = {\datatable}{Document Type},
            xticklabel style={rotate=90,xshift=-5ex,anchor=mid east},
            ymajorgrids,
            draw group line={Publication Year}{2018}{2018}{-4ex}{7pt},
            draw group line={Publication Year}{2019}{2019}{-4ex}{7pt},
            draw group line={Publication Year}{2020}{2020}{-4ex}{7pt},
            draw group line={Publication Year}{2021}{2021}{-4ex}{7pt},
            ]
            \addplot [ybar,draw = blue,fill=blue!50, nodes near coords] table 
                     [x expr=\coordindex,
                      y=count,
                      ] {\datatable};
         \end{axis}
    \end{tikzpicture}
    \caption{Distribution of selected literature type by year.}
    \label{fig:literature-types}
\end{figure}



\section{Research Question 1: What are the current approaches for \acrlong{sc} vulnerability detection?}


Many tools and methods for vulnerability detection have been developed over recent years. This includes both static and dynamic vulnerability techniques, as well as tools based on \acrfull{ml}. These tools can be categorized in terms of their primary function. This includes symbolic execution, syntactical analysis, abstract interpretation, data flow analysis, fuzzy testing, formal verification and machine learning. In the following sections, the identified vulnerability detection tools are summarized, compared, and analyzed in detail (up to December 2021).

\todo{Grap hover distributtion of tools of type... symbolic, ml, static, dynamic, etc...}
\todo{Add snowballing effect for sources}

\todo{Use master section as: Static and Dynamic Vulnerability Detection Methods?}

Static vulnerability detection methods are performed without actually executing programs. The analysis is performed by examining the source code or \gls{bytecode} of the smart contract. Another group of analysis is so-called Dynamic program analysis. This is a form of analysis performed by executing programs on a real or virtual processor. This is in contrast to static program analysis. In order to detect vulnerabilities, the program is monitored during execution. However, in order to be effective, sufficient inputs needs to be provided/tested.

What is it the other tools have done differently? Main differences, etc...
Include a view on WHICH vulnerabilities can be detected by which tools.\\

\todo{keep 1.2textwidth (overfull margin)?}
\todo{Write about yamashita2019potential - Hyperledger Fabric}
\todo{Include HFContractFuzzer?}
\todo{Include Seraph?}

%\begin{table}[htp]
\begin{ThreePartTable}
    \newcolumntype{Y}{>{\centering\arraybackslash}X}
    \newcolumntype{R}{>{\raggedright\arraybackslash}X}
    \newcommand\T{\rule{0pt}{2.6ex}}       % Top strut or \bigstrut[t]
    \newcommand\B{\rule[-1.2ex]{0pt}{0pt}} % Bottom strut or \bigstrut[b]
    \def\arraystretch{1.5}
    \setlength\tabcolsep{6pt} % <--- important, (default 6pt)
    \setlength{\LTleft}{-20cm plus -1fill}
    \setlength{\LTright}{\LTleft}
    \footnotesize
    %\centering
    \begin{center}
    \begin{TableNotes}
        \item[a] \label{tn:decompiled-sourcecode} Source code input that is just compiled down to bytecode is marked with "*".
    \end{TableNotes}
    %\begin{adjustbox}{center}
    \keepXColumns
    \begin{tabularx}{1.2\textwidth}{cllRRR}
            \caption{Existing static smart contract vulnerability detection tools.}\label{tab:static-tools}\\
            \toprule
            \textbf{Refs.} & \textbf{Year} & \textbf{Name} & \textbf{Assistive technology} &  \textbf{Capability} & \textbf{Input\tnotex{tn:decompiled-sourcecode}}\\
            \hline     
        \endfirsthead
            \caption{(\textit{Continued}) Existing static smart contract vulnerability detection tools.}\\
            \toprule
            \textbf{Refs.} & \textbf{Year} & \textbf{Name} & \textbf{Assistive technology} &  \textbf{Capability} & \textbf{Input\tnotex{tn:decompiled-sourcecode}}\\
            \hline
        \endhead
            \midrule
            \multicolumn{6}{r}{\small(\textit{Continued on next page})}\\
        \endfoot
            \insertTableNotes\\
        \endlastfoot

        \multicolumn{6}{l}{\cellcolor{gray!10}{\textbf{Symbolic execution}}} \bigstrut \\*
        \cite{luu2016making} & 2016 & \textsc{Oyente} & -- & Multi-class & Solidity*, \newline EVM bytecode \\
        \cite{albert2018ethir} & 2018 & \textsc{EthIR} & -- & General-purpose (depends on high-level verifier) & Solidity*, \newline EVM bytecode \\
        \cite{zhou2018security} & 2018 & SASC & Topological analysis and syntax analysis & Multi-class & Solidity  \\
        %%% currently  here...
        \cite{mueller2018mythril} & 2018 & Mythril & Taint analysis and symbolic model checking & Multi-class & EVM bytecode \\
        \cite{zhang2019mpro} & 2018 & MPro & Taint analysis, symbolic model checking and data-flow analysis & Multi-class & EVM bytecode \\
        \cite{nikolic2018finding} & 2018 & Maian & Concrete validation & Multi-class, dynamic & Solidity, \newline EVM bytecode \\
        \cite{tsankov2018securify} & 2018 & \textsc{Securify} & Abstract interpretation & Binary decision & Solidity*, \newline EVM bytecode \\
        \cite{albert2019safevm} & 2019 & \textsc{SAFEVM} & Symbolic model checking & General-purpose (depends on C verifier) & Solidity*, \newline EVM bytecode \\
        \cite{akca2019solanalyser} & 2019 & SolAnalyser & Code instrumentation and execution trace analysis & Multi-class & Solidity \\
        \cite{mossberg2019manticore} & 2019 & Manticore & -- & & EVM bytecode \\
        \cite{chien2020ra} & 2020 & RA & -- & Reentrancy & EVM bytecode \\
        
        \noalign{\penalty-5000}
        \multicolumn{6}{l}{\cellcolor{gray!10}{\textbf{Syntax analysis}}} \bigstrut \\*
        \cite{tikhomirov2018smartcheck} & \citeyear{tikhomirov2018smartcheck} & SmartCheck & Topological analysis & Multi-class & Solidity \\
        \cite{lu2019neucheck} & \citeyear{lu2019neucheck} & NeuCheck & -- & Multi-class & Solidity \\
        \cite{ma2020rejection} & \citeyear{ma2020rejection} & ReJection & -- & Reentrancy & Solidity \\
        \cite{yamashita2019potential} & \citeyear{yamashita2019potential} & -- & -- & Multi-class & Go chaincode (Hyperledger Fabric) \\
        
        \noalign{\penalty-5000}
        \multicolumn{6}{l}{\cellcolor{gray!10}{\textbf{Abstract interpretation}}} \\*
        \cite{kalra2018zeus} & 2018 & Zeus & Symbolic model checking & & Solidity, Go, (Java, Python, JavaScript, etc.) \\
        \cite{brent2018vandal} & 2018 & Vandal & Logic-driven analysis & Multi-class & Bytecode \\
        \cite{grech2018madmax} & 2018 & MadMax & Decompilation & Multi-class gas-related & EVM bytecode \\
        
        \noalign{\penalty-5000}
        \multicolumn{6}{l}{\cellcolor{gray!10}{\textbf{Data Flow Analysis}}} \\*
        \cite{feist2019slither} & 2019 & Slither & Taint analysis & Multi-class & Solidity \\
        \cite{ye2020clairvoyance} & 2020 & \textsc{Clairvoyance} & Taint analysis & Reentrancy & Solidity \\
        \cite{ali2021sescon} & 2020 & SESCon & Taint analysis and Syntax analysis & Multi-class & Solidity \\
        
        \noalign{\penalty-5000}
        \multicolumn{6}{l}{\cellcolor{gray!10}{\textbf{Fuzzing}}} \\*
        \cite{jiang2018contractfuzzer} & 2018 & ContractFuzzer & -- & ?? & EVM \acrshort{abi}, EVM bytecode \\
        \cite{liu2018reguard} & 2018 & ReGuard & -- & ?? & Solidity, EVM bytecode \\
        \cite{he2019learning} & 2019 & ILF & Symbolic execution & ?? & EVM bytecode \\
        \cite{grieco2020echidna} & 2020 & Echidna & -- & ?? & Solidity, Vyper \footnote{Pythonic Smart Contract Language for the EVM \url{https://vyper.readthedocs.io/en/stable/}} \\
        \cite{nguyen2020sfuzz} & 2020 & sFuzz & -- & ?? & EVM bytecode \\
        \bottomrule
    \end{tabularx}
    \end{center}
    %\end{adjustbox}
\end{ThreePartTable}
%\end{table}


\subsection{Symbolic Execution}
Symbolic execution is a ...

\paragraph{\textsc{Oyente}}
\textsc{Oyente} is one of the earliest Ethereum \acrshort{sc} vulnerability detection tool, developed by \textcite{oyente2016making} in \citeyear{oyente2016making}. The tool consists of four main components, named CFGBuilder, Explorer, CoreAnalysis, and Validator. The CFGBuilder component builds a \acrfull{cfg} of a smart contract. The Explorer component is a symbolic execution engine that explores the \acrshort{cfg}, using the \gls{z3} constraint solver for determining if a branch condition is either provably true or provably false along the current path. The CoreAnalysis component analyzes the explored CFG to detect vulnerabilities. The Validator component is finally used for eliminating false positives. \textsc{Oyente} uses EVM bytecode as its input. \textsc{Oyente} has paved the way for a lot of subsequent research. It is able to detect Call Stack Risk, Reentrancy Risk, Transaction Order Risk and Timestamp Risk.

\paragraph{\textsc{EthIR}}
\textcite{albert2018ethir} analyzes EVM bytecode based on the rule-based representations of \acrshort{cfg} produced by an improved version of \textsc{Oyente} \cite{oyente2016making}. The improvement primarily consist of including all possible jump addresses, whereas originally \textsc{Oyente} only stores the last jump address. This allows \textsc{EthIR} to produce a complete \acrshort{cfg}, containing both control-flow and data-flow information of the \acrshort{sc} EVM bytecode. From this, \textsc{EthIR} generates guarded rules for checking for conditional and unconditional jump instructions. This enables the application of (existing) high-level analyses to infer properties of the EVM code. \textcite{albert2018ethir} uses the high-level static analyzer SACO (Static Analyzer for Concurrent Objects) for checking conditional and unconditional jump instructions.

\paragraph{SAFEVM}
SAFEVM is an verification tool for Ethereum smart contracts that makes use of existing verification engines for C programs. \textcite{albert2019safevm} uses \textsc{Oyente} and \textsc{EthIR} in order to produce a rule-based representation of EVM bytecode or Solidity. This is then converted into a special C program. Existing analysis tools are then used to verify the security of the converted C program, and a report with the verification results is outputted.

\paragraph{\textsc{SASC}}
SASC \cite{zhou2018security} analyzes Ethereum \acrshortpl{sc} written in Solidity, and is able to detect the same logical vulnerabilities as that of \textsc{\textsc{Oyente}}. SASC primarily makes use of symbolic execution in order to detect vulnerabilities. However, the tool also makes use of syntax analysis, combined with topological analysis, in order to locate a detected risk to a specific function.

\paragraph{SolAnalyser}
\todo{Is this symbolic execution, or trace analysis?}
SolAnalyser purposed by \textcite{akca2019solanalyser} uses code instrumentation and execution trace analysis in order to detect vulnerabilities in Solidity \acrshortpl{sc}. The authors proposes a fully automated pipeline for detecting vulnerabilities, as well as evaluating the tool with the help of creating a \acrshort{sc} mutation tool. 

\paragraph{Mythril}
Mythril, developed by \textcite{mueller2018mythril} is a command line tool, combining symbolic execution, with taint analysis and \acrshort{smt}. Mythril takes in EVM bytecode as input. In addition, Mythril also provides interfaces to allow for developers to write custom vulnerability detection logic. In order to cover the situation where a contract is called upon multiple times, Mythril simulates this through conducting multiple symbolic executions (two by default). 

\paragraph{MPro}
MPro by \textcite{zhang2019mpro} is a fully automated and scalable security scanning tool for Ethereum \acrshort{sc}. MPro combines the existing tools Mythril \cite{mueller2018mythril} and Slither \cite{feist2019slither}, leveraging both static and symbolic analysis to prune unnecessary execution paths and achieve \(n\) times efficiency increase than that of Mythril.

\paragraph{\textsc{Maian}}
\textsc{Maian} \cite{nikolic2018finding} is a symbolic execution tool for specifying and inferring trace vulnerabilities. \textcite{nikolic2018finding} points out that most existing tools ignore problems related to calling a contract multiple times. Contracts containing trace vulnerabilities could: lock funds indefinitely; allow for transfer founds to any address; be killed by anyone. Based on these attributes, \textsc{Maian} marks vulnerable contracts in three categories, greedy, prodigal, and suicidal. \textsc{Maian} takes EVM bytecode as input. Along with user-defined analysis targets, this allows for confirming the presence of a trace vulnerability.

\paragraph{\textsc{Securify}}
\textsc{Securify}\cite{tsankov2018securify} is a security analysis tool for Ethereum \acrshort{sc} that combines abstract interpretation with symbolic execution. Thee tool automatically classifies behaviors of a contract into three categories, compliance (matched by compliance properties), violation (matched by violation properties), and warning (matched by neither). \textsc{Securify} takes in EVM bytecode as input, along with a security model defined with a new domain-specific language. The use of a domain-specific language, enables users to express new vulnerability patterns as they emerge.

\todo{Securify has a new version named Securify2}

\paragraph{Manticore}
\todo{Investigate the effort neeeded to implement an other execution environment.}
Manticore \cite{mossberg2019manticore} is a flexible security analysis tool. It is based on symbolic execution and satisfiability modulo theories. It provides comprehensive API access, allowing the user to build custom symbolic execution-based tools. Further, Manticore's symbolic engine logic is decoupled from the details of a particular execution environment. This allows for support of various execution environments, such as both traditional environments(e.g., x86, ARM, and WASM), as well as Ethereum.

\paragraph{RA} 
RA by \textcite{chien2020ra} uses symbolic execution in order to detect re-entrancy vulnerabilities. The authors identifies that existing literature only report only program behavior via CFGs obtained within a single contract. Hence, RA focuses on analyzing re-entrancy attacks including inter-contract behavior. RA can analyze the vulnerabilities precisely, without false positives and false negatives.

\subsection{Syntactical analysis}
Syntactical analysis is a method to analyze computer programs by parsing the source code into a tree structure. This tree is then analyzed for its relation of each component.???

\paragraph{SmartCheck}
SmartCheck is an extensible analysis tool by \textcite{tikhomirov2018smartcheck} based on syntax analysis. SmartCheck takes Solidity source code as input and translates it into an XML parse tree as an \acrshort{ir}. This \acrshort{ir} is then checked against XPath patterns in order to detect coding issues. The authors classifies Solidity code issues into four categories, Security, Functional, Operational and Developmental. For example, SmartCheck is able to detect Solidity specific coding issues such as style guide violations, as well as the more common blockchain security vulnerabilities like Reentrancy problems. \todo{Findsomee way to formulate this...}

\paragraph{NeuCheck}
\textcite{lu2019neucheck} introduces NeuCheck, a cross-platform \acrshort{sc} syntax analysis tool for Ethereum. NeuCheck generates a syntax tree from Solidity source code, and generates an XML-based \acrshort{ir}. The open-source tool dom4j \footnote{\url{https://dom4j.github.io}} is then leveraged for parsing this tree and completing the analysis.

\paragraph{ReJection}
\textcite{ma2020rejection} purpose a method for detecting \acrshort{sc} reentrancy vulnerability detection based on analysis of \acrshortpl{ast}. The analysis conducted by ReJection is comprised of four steps. An \acrshort{ast} is generated from Solidity source code with the \acrshort{sc} compiler solc \footnote{\url{https://github.com/ethereum/solidity}}. This \acrshort{ast} is then pruned for redundant information. ReJection then traverses the \acrshort{ast}, analyzing and recording key information related to conditions of a reentrancy vulnerability. Finally, the tool decides whether there actually exists a reentrancy vulnerability,  depending on some determination rules summarized by the authors.


\subsection{Abstract interpretation}
Abstract interpretation is a method to analyze computer programs by interpreting the source code as a set of logical expressions. This set of logical expressions is then analyzed for its relation of each component. \todo{Rewrite this info.}

\paragraph{Zeus}
Zeus purposed by \textcite{kalra2018zeus} combines both abstract interpretation, symbolic model checking and constrained horn clauses. Model checking is verification method where a a system is modeled into a finite state machine. This is then used for verifying whether the system meets certain criteria. Zeus takes \Gls{solidity} \acrshort{sc} code as input, and translates it into an low-level \acrshort{ir} called \gls{llvmir}. \gls{llvm} is a compiler toolchain, that supports a large ecosystem of code analysis tools. Along with the \gls{llvm} code, Zeus also requires a user to provide a set of policies \todo{refs..} that are used in order to .... Finally, existing \gls{llvm} Verification based tools are used on the constrained horn clauses to identify vulnerabilities.
\todo{include gray litterature - Zeus!!!}

\paragraph{MadMax}
MadMax is a gas-focused vulnerability detection tool by \textcite{grech2018madmax}. The authors creates a pipeline consisting of a control flow analysis based decompiler that disassembles EVM bytecode into a structured low-level \acrshort{ir}. This is then analyzed in DataLog \cite{datalog} by representing the \acrshort{ir} as DataLog \cite{datalog} facts. Along with data flow analysis along with context-sensitive flow analysis and memory layout modeling, the authors are able to automatically detect out-of-gas vulnerabilities.

\paragraph{EtherTrust}
\textcite{grishchenko2018foundation} 
\todo{EtherTrust}


\subsection{Data Flow Analysis}
Data flow analysis is a method to analyze computer programs by analyzing the flow of data through the source code. Often taint analysis... \todo{Rewrite this info.} Can analyze large programs, compared to, for example, symbolic execution.

\paragraph{Slither}
Slither \cite{feist2019slither} is a highly scalable static analysis tool which analyzes a smart contract source code at the intermediate representation SlithIR level. The \acrshort{ir} is constructed on the basis of a \acrlong{cfg}. Slither then applies both data-flow analysis and taint analysis techniques in order to detect vulnerabilities.

\paragraph{\textsc{Clairvoyance}}
\textsc{Clairvoyance} presents a static reentrancy detection approach \cite{ye2020clairvoyance}. The tool models cross-function and cross-contract behaviors, in order to enable a more sound analysis than Slither \cite{feist2019slither}, \textsc{Oyente} \cite{oyente2016making} and \textsc{Securify} \cite{tsankov2018securify}. \textsc{Clairvoyance} applies cross-contract static taint analysis to find reentrancy candidates, then integrates path protective techniques to refine the results. The authors claim that the tool significantly outperforms the three static tools in terms of precision and accuracy.

\paragraph{SESCon}
\textcite{ali2021sescon} presents a solution to detect \acrshort{sc} vulnerabilities through static analysis. SESCon is based on XPath and taint analysis. The tool first generates a AST based on Solidity code, and applies XPath queries in order to find simple vulnerability patterns. Then, a deeper analysis is conducted based on taint analysis. For this analysis, to generate vulnerability patterns, the authors extract state variables, local variables, control flow, graph dependency of functions, and payable and non-payable functions. \textcite{ali2021sescon} claims that SESCon outperforms other analyzers and can accurately detect up to 90\% of known vulnerability patterns.

Conclusion...
Symbolic execution is the most popular vulnerability detection method. It also seems that it is the most reliable method. Most mature.



\subsection{Fuzzing test}
Fuzzing is ....

\paragraph{ContractFuzzer}
\textsc{jiang2018contractfuzzer} is a fuzzing tool for detecting several types of vulnerabilities in \acrshortpl{sc}. ContractFuzzer generates random inputs according to the \acrfull{abi} of the \acrshort{sc} to test. It then executes the contract with these inputs and records the results. ContractFuzzer defines a set of predefined test \glspl{oracle} that describes specific vulnerabilities. These are used to perform the security analysis, and detect potential vulnerabilities. The authors evaluates thee tool and reports that it has lower false-positive rate than \textsc{Oyente}. However, due to the randomness of the inputs, only limited system behavior is possible to cover.

\paragraph{ReGuard}
ReGuard by \textcite{liu2018reguard} is another fuzzing tool, able to detect re-entrancy vulnerabilities. ReGuard accepts both Solidity source code and EVM bytecode as input. It converts the input into a C++ program via an \acrshort{ir}. This \acrshort{ir} is an \acrshort{ast} if the input is Solidity code, and \acrshort{cfg} if it takes in EVM bytecode. ReGuard then generates random inputs and performs the fuzzing. ReGuard records the execution traces and feeds them into a reentrancy automata. Finally, a detection report is generated, identifying the location of the vulnerable code, along with an attack transaction that triggers the bug.

\paragraph{ILF}
Imitation Learning based Fuzzer (ILF) \cite{he2019learning} combines fuzzing testing with symbolic execution, through the use of imitation learning. By applying an appropriate neural network, ILF is able to learn a fuzzing probabilistic strategy, thereby imitating the behavior of symbolic execution. This way, the fuzzer is able to achieve better coverage, and thus, more vulnerabilities.

\paragraph{Echidna}
Echidna is a \acrshort{sc} fuzzing tool purposed by \textcite{grieco2020echidna}, supporting user-defined analysis. Echidna consists of two main components: pre-processing and fuzzing campaign. First, the static analysis framework Slither \cite{feist2019slither} is used to extract various information. Then it applies fuzzing based on the \acrshort{abi} to detect violations in custom user-defined properties and assertions. Echidna is able to test both Solidity and Vyper \footnote{Pythonic Smart Contract Language for the EVM \url{https://vyper.readthedocs.io/en/stable/}} \acrshortpl{sc}.

\paragraph{sFuzz}
Inspired by American Fuzzy Lop (AFL) \footnote{Famous C program fuzzer}, \textcite{nguyen2020sfuzz} created an adaptive fuzzing tool for Ethereum \acrshortpl{sc}. It also employs an efficient and lightweight adaptive strategy for selecting seeds. This is because branches guarded with strict conditions are expensive to cover. The authors report a speedup of more than two orders of magnitude compared to ContractFuzzer.

\subsubsection{Validation}
ContractLarva (runtime verification)
Maian ( "combines symbolic analysis and concrete validation to inspect the smart contract’s bytecode. In concrete validation, the contract is executed on a fork of Ethereum for tracing and vali- dation.")
Sereum 

\subsection{Formal Verification}
Formal Verification is a method to mathematically verify the correctness of a program. \todo{Rewisit this info.}

\subsection{Machine Learning for Vulnerability Detection}
"Several works have attempted to perform automated contract scan- ning using machine learning techniques. We discuss their working mechanisms and limitations below."

\begin{ThreePartTable}
    \newcolumntype{Y}{>{\centering\arraybackslash}X}
    \newcolumntype{R}{>{\raggedright\arraybackslash}X}
    \def\arraystretch{1.5}
    \setlength\tabcolsep{6pt} % <--- important, (default 6pt)
    \setlength{\LTleft}{-20cm plus -1fill}
    \setlength{\LTright}{\LTleft}
    \footnotesize
    \begin{center}
    \begin{TableNotes}
        \item[a] \label{tn:ml-description} Name of the tool or framework. If no name exists, a short description or "--" is used.
    \end{TableNotes}
    \keepXColumns
    \begin{tabularx}{1.2\textwidth}{cllRRRR}
            \caption{Existing ML-based smart contract vulnerability detection tools.}\label{tab:ml-tools}\\
            \toprule
            \textbf{Refs.} & \textbf{Year} & \textbf{Desc.\tnotex{tn:ml-description}} & \textbf{Method} & \textbf{Feature engineering} &  \textbf{Capability} & \textbf{Input}\\
            \hline
        \endfirsthead
            \caption{(\textit{Continued}) Existing static smart contract vulnerability detection tools.}\\
            \toprule
            \textbf{Refs.} & \textbf{Year} & \textbf{Desc.\tnotex{tn:ml-description}} & \textbf{Method} & \textbf{Feature engineering} &  \textbf{Capability} & \textbf{Input}\\
            \hline
        \endhead
            \midrule
            \multicolumn{6}{r}{\small(\textit{Continued on next page})}\\
        \endfoot
            \insertTableNotes\\
        \endlastfoot

        \cite{MISSING} & \citeyear{MISSING} & ESCORT & LSTM, transfer learning & & Multi-label & Bytecode\\
        \cite{MISSING} & \citeyear{MISSING} & Towards Sequential & \acrshort{lstm} & & Binary decision & Opcode\\
        MISSING\cite{huang2018hunting} & \citeyear{huang2018hunting} & Color-inspried & \acrshort{cnn} & ??  & Multi-label & Bytecode\\
        \cite{momeni2019machine} & \citeyear{momeni2019machine} & -- & \acrshort{ast} & Multi binary decision & Solidity \\
        \cite{xing2020anew} & \citeyear{xing2020anew} & Slicing matrix & ?? & EVM bytecode \\
        \cite{qian2020towards} & \citeyear{qian2020towards} & -- &  \acrshort{att-blstm} & Contract snippet, word embedding & Reentrancy & Solidity \\
        MISSING\cite{gogineni2020multiclass} & \citeyear{gogineni2020multiclass} & NLP-inspried & AWD-LSTM & ?? & Multi-class & Opcode\\
        MISSING \cite{zhuang2020smart} & \citeyear{zhuang2020smart} & Graph NN-based & GNN & ?? & Multi-class & Source code\\
        \cite{xu2021security} & \citeyear{xu2021security} & -- & \acrshort{ast} & ?? & Solidity \\
        \cite{wang2021contractward} & \citeyear{wang2021contractward} & ContractWard & XGBoost & Bigram model & Binary decision & Opcode\\
        \cite{zhao2021gan} & \citeyear{zhao2021gan} & -- & \acrshort{gan} & Code embedding & Reentrancy & EVM bytecode\\

        \bottomrule
    \end{tabularx}
    \end{center}

\end{ThreePartTable}



\todo{Determine category of ML-based tools.}
\todo{Use multi-class, or binary decision categories?}
\todo{Use the input as sections?, Eg. AST, bytecode, source code, llvm, etc.}
\todo{Change some multi-class too multi-label, and add description of each class.}

\subsubsection{Average Stochastic Gradient Descent Weighted Dropped LSTM}
\subsubsection{Convolutional Neural Network}
\subsubsection{Graph Neural Network}
\subsubsection{AWD-LSTM based}


\subsubsection{\acrfull{dnn}}
\paragraph{VSCL}
VSCL, purposed by \textcite{mi2021vscl}, is a framework for ... VSCL accepts EVM bytecode as input, and disassembles this into opcodes. A \acrshort{cfg} is constructed for allowing the model to understand program runtime behavior. Further, n-gram and \acrfull{tfidf} technique is used for generating numeric values (vectors) for features of \acrshortpl{sc}. Finally, the generated feature matrix is used as input of the \acrshort{dnn} model. A real-world dataset is collected and labeled with the help of three tools, Oyente \cite{oyente2016making}, Mythril \cite{mueller2018mythril}, and Vandal \cite{brent2018vandal}.

\subsubsection{\acrfull{gan}}
\textcite{zhao2021gan} propose a reentrant vulnerability detection model based on word embedding, similarity detection, and \acrfullpl{gan}. The model consists of six phases. Firstly, text input and semantic analysis is conducted. Then code embedding is done in step two utilizing FastText \cite{bojanowski2017enriching} for vectorization. Thirdly, contract statement matrix and vulnerability statement matrix are generated. Then a detailed detection is completed, enabling location of the actual line of vulnerable code. The discriminator is generated in the next step, finally followed by building the generator. Through this method, the authors solves the shortcomings of traditional manual data collection and manual marking. The authors report to achieve 92\% detecting accuracy for reentrant vulnerable contracts.

\subsubsection{\acrfull{lstm}}
\paragraph{ESCORT}
ESCORT \cite{gogineni2020multiclass} utilizes deep learning in order to detect multiple \acrshort{sc} vulnerabilities. The model is based on a \acrfull{lstm} network. This model is trained on \acrshort{sc} bytecode from the Ethereum blockchain. A tool the authors name ContractScraper is used to extract the opcodes from the \acrshort{sc}. Further, ESCORT supports lightweight transfer learning on unseen security vulnerabilities, thus it is extensible and generalizable. Evaluation of ESCORT indicates an average accuracy of 95\% (F1 score) across various vulnerability classes.

\subsubsection{\acrfull{att-blstm}}
\textcite{qian2020towards} attempt to utilize a deep learning-based approach based on \acrfull{att-blstm} for detecting reentrancy bugs. The authors also purpose a contract snippet representation for \acrshortpl{sc}, intended for capturing essential semantic information and control flow dependencies specifically related to reentrancy problems. These snippets are then converted to vectors through tokenization, and with the help of the word embedding tool word2vec \cite{mikolov2013distributed}. The authors report good experimental results for detecting reentrancy vulnerabilities.

% Feature extraction
\subsubsection{Bigram based}
\paragraph{ContractWard}
ContractWard \cite{wang2021contractward} implements a smart contract vulnerability detection tool based on machine learning. It is a multi-label classifier that can detect multiple vulnerabilities. \textcite{wang2021contractward} employs a method based on extracting bigram features from simplified opcodes. ContractWard accepts bytecode of the \acrshort{sc} as input, and outputs a binary decision. The authors targets six vulnerabilities and employ three supervised ensemble classification algorithms, namely, XGBoost, AdaBoost and \acrshort{rf}, and two simple classification algorithms, namely, \acrshort{svm} SVM and \acrshort{knn}. XGBoost is selected as the best performing classifier algorithm.

\subsubsection{Abstract Syntax Tree based}
\todo{How to structure in subcategories? (no name)}
\paragraph[]{TODO NAME}
\textcite{momeni2019machine} presents a machine learning predictive model that detects patterns of security vulnerabilities in \acrshortpl{sc}. The authors trained several commonly used supervised binary classifiers. This includes including Support Vector Machine (SVM), Neural Network (NN), Random Forest (RF) and Decision Tree (DT). For creating the dataset, more than 1000 \acrshortpl{sc} were collected from Etherscan \footnote{\url{https://etherscan.io}}. For each of the contracts, an \acrshort{ast} were generated. The authors then extract 17 features from  the \acrshortpl{ast}. For labeling the data, the existing static analysis tools Mythril \cite{mueller2018mythril} and Slither \cite{feist2019slither} were used. The authors report that the investigated security vulnerabilities were independent to each other. Hence, each of the classifiers were trained for each vulnerability. The evaluation results reports an average accuracy of 95\% for the various vulnerabilities.
\todo{The approach described in this paper can be applied to other languages and blockchain platforms}

\paragraph[]{TODO NAME}
\textcite{xu2021security} provides an machine learning approach to detect vulnerabilities in \acrshortpl{sc} based on \acrlongpl{ast}. The authors first generate \acrshortpl{ast} for the contracts to analyze. They then get the \acrshortpl{ast} of some malicious contracts. A feature vector is then generated based on common child nodes of the \acrshortpl{sc} \acrshortpl{ast}. These vectors are then labeled with the help of existing vulnerability analysis tools, such as Slither \cite{feist2019slither} and Ethainter \cite{TODO}. Machine learning classification algorithms such as \acrshort{knn} and \acrshort{sgd} are then used to train a model.

\subsubsection{Slicing matrix}
\textcite{xing2020anew} points out the importance of local code vulnerability. To tackle this, the authors propose a new feature extraction method named slicing matrix. The size of the feature matrix is dependent on the number of contract segments, as well as the number of different opcodes found in the dataset. Experiment results show that slice matrix improves the accuracy of vulnerable contract identification. However, the authors stress the need for better integration/use of the slice matrix in their best performing classification algorithm, namely \acrlong{rf}.

\section{Research Question 2: What is the current research on cross-chain \acrlong{sc} vulnerability detection?}

"Cross-chain vulnerability detection is a method for detecting vulnerabilities in smart contract code across multiple blockchains. Little efforts have been made to develop a cross-chain vulnerability detection framework. We discuss the challenges and opportunities of cross-chain vulnerability detection."


\textcite{kalra2018zeus} provides a tool called Zeus. Zeus translates the \Gls{solidity} \acrshort{sc} language into LLVM-IR language. \gls{llvm} is a compiler toolchain, that supports a large ecosystem of code analysis tools. However, the \gls{llvmir} is very is an \acrshort{ir} that  that can be used to detect vulnerabilities in the \acrshortpl{sc} language.

\textcite{lewispye2021general} conducts a systematic literature mapping identifying A General Framework for the Security Analysis of Blockchain Protocols

Besides the articles listed above, to my greatest extent, i have not been able to find any other research directly targeting cross-chain \acrlong{sc} vulnerability detection. However, there are some interesting solutions that demonstrates some cross-chain support.

\todo{Zeus: Emphasize on the need for policies and that it is a prototype implementation.} The most promising tool is Zeus by \textcite{kalra2018zeus} that allows for cross-chain compatibility through the use of \gls{llvm}. By using \gls{llvm}, any \acrshort{sc} language can be translated into the \gls{llvm} language. This is also the only existing tool that also demonstrates cross-chain support through a prototypal mock implementation for Hyperledger Fabric \cite{hyperledger-fabric}. The implementattion of Zeus is also not available.

Another solution is the \acrshort{sc} language \textsc{Scilla} by \textcite{sergey2018scilla}. This is supposed to be an type of intermediate language based on communicating automata. However, there are no automatic translation tools for converting another language into \textsc{Scilla}. Other similar solutions include converting \gls{solidity} into \gls{f-star}; a general-purpose functional programming language with effects aimed at program verification \cite{f-star}.


\cite{momeni2019machine}, \cite{wang2021contractward} (ContractWard) eg.. most current ML solutions states that their approach is applicable to other languages and blockchain platforms. However, the compatibility assumes that the entire training process is repeated for the other target. Firstly, this is not currently feasible, as the share volume of smart contracts is not large enough on other platforms than Ethereum.


\section{Research Question 3: How to make \acrlong{sc} vulnerability detecting possible cross-chain?}

Draft:
Begin with using ML.. Then discuss existing solutions for AST analysis cross languages. 
Present research about cross language analysis. AST solutions, simplifications etc.

\textcite{matsumura2021vulnerabilities} suggest \acrshortpl{ml} for automatic vulnerability detection as future work. This because it is a promising vulnerability detection technique for traditional software, it doesn’t rely heavy on human-defined rules and has obtained competitive results.

for \acrshortpl{sc} vulnerability detection. This because \acrshortpl{ml} has been shown to be a promising vulnerability detection technique 

since it is a promising vulnerability detection technique even for traditional software [7,15], does not rely heavily on rules defined by human experts and has obtained competitive results; research proposing solutions involving dynamic analysis or software testing, seeking to deal with the limitations of the execution environment.
\chapter{Research results}
\label{chap:results}
This chapter presents the results of this \acrfull{slr}. Firstly, a descriptive analysis of the selected literature is presented. Following are the results for each of the research questions defined in \cref{sec:research-questions}.

\section{Descriptive analysis}
This study analyzes a total of ?? research papers, published between 2018 and 2021. No publications earlier than 2018 were available. From then on, the number of publications has drastically increased. An distribution of selected literature type ordered by year is illustrated in \cref{fig:literature-types}. It shows an upwards trend in term of publications. It is also to be noted that the majority of the publications are conference proceedings. This is to be expected, as the field of smart contract security is a relative new field.

\newcounter{groupcount}
\pgfplotsset{
    draw group line/.style n args={5}{
        after end axis/.append code={
            \setcounter{groupcount}{0}
            \pgfplotstableforeachcolumnelement{#1}\of\datatable\as\cell{%
                \def\temp{#2}
                \ifx\temp\cell
                    \ifnum\thegroupcount=0
                        \stepcounter{groupcount}
                        \pgfplotstablegetelem{\pgfplotstablerow}{[index]0}\of\datatable
                        \coordinate [yshift=#4] (startgroup) at (axis cs:\pgfplotsretval,0);
                    \else
                        \pgfplotstablegetelem{\pgfplotstablerow}{[index]0}\of\datatable
                        \coordinate [yshift=#4] (endgroup) at (axis cs:\pgfplotsretval,0);
                    \fi
                \else
                    \ifnum\thegroupcount=1
                        \setcounter{groupcount}{0}
                        \draw [
                            shorten >=-#5,
                            shorten <=-#5
                        ] (startgroup) -- node [anchor=base, yshift=0.5ex] {#3} (endgroup);
                        %] (startgroup) -- node [anchor=north] {#3} (endgroup);
                    \fi
                \fi
            }
            \ifnum\thegroupcount=1
                        \setcounter{groupcount}{0}
                        \draw [
                            shorten >=-#5,
                            shorten <=-#5
                        ] (startgroup) -- node [anchor=base, yshift=0.5ex] {#3} (endgroup);
                        %] (startgroup) -- node [anchor=north] {#3} (endgroup);
            \fi
        }
    }
}

\begin{figure}[htp]
    \centering
    \begin{tikzpicture}
        \pgfplotstableread[col sep = comma]{data/publication-year-type.csv}\datatable
        \begin{axis}[
            width=\textwidth,
            height=8cm,
            ymin=0,
            %ymax=23,
            %ylabel={Percentagem},
            xtick=data,
            xticklabels from table = {\datatable}{Document Type},
            xticklabel style={rotate=90,xshift=-5ex,anchor=mid east},
            ymajorgrids,
            draw group line={Publication Year}{2018}{2018}{-4ex}{7pt},
            draw group line={Publication Year}{2019}{2019}{-4ex}{7pt},
            draw group line={Publication Year}{2020}{2020}{-4ex}{7pt},
            draw group line={Publication Year}{2021}{2021}{-4ex}{7pt},
            ]
            \addplot [ybar,draw = blue,fill=blue!50, nodes near coords] table 
                     [x expr=\coordindex,
                      y=count,
                      ] {\datatable};
         \end{axis}
    \end{tikzpicture}
    \caption{Distribution of selected literature type by year.}
    \label{fig:literature-types}
\end{figure}



\section{Research Question 1: What are the current approaches for \acrlong{sc} vulnerability detection?}


Many tools and methods for vulnerability detection have been developed over the recent years. These tools can be categorized in terms of their primary function. Primarily, they can be divided into three categories: Static Vulnerability Detection, Dynamic Vulnerability Detection, and Machine Learning based Vulnerability Detection. In the following sections the identified vulnerability detection tools are summarized, compared and analyzed in detail (up to December 2021).

\todo{Grap hover distributtion of tools of type... symbolic, ml, static, dynamic, etc...}
\todo{Add snowballing effect for sources}
\todo{Assess Seraph}
\todo{remove this table??}
The following table lists the tools and their respective categories.

\begin{table}[htp]
    \centering
    \caption{Vulnerabilities enumeration.}
    \label{tab:vulnerabilities-enumeration}
    \begin{tabular}{cllc}
        \toprule
        \# & \textbf{Vulnerability name} & \# & \textbf{Vulnerability name} \\
        \midrule
        1 & Integer Overflow & 4 & Stack Size Limit (deprecated) \\ 
        2 & Integer Underflow & 5 & Timestamp Dependency \\ 
        3 & Transaction-Ordering Dependence & 6 & Reentrancy \\
        
        \bottomrule
    \end{tabular}
\end{table}



\begin{table}[htp]
    \newcolumntype{Y}{>{\centering\arraybackslash}X}
    %\def\arraystretch{1.5}
    \centering
    \caption{Comparison of vulnerability types detectable by existing tools.}
    \label{tab:supported-vulnerabilities}
    \begin{threeparttable}
        \begin{tabularx}{\textwidth}{c*{6}{|Y}}
            \toprule
            \multirow{2}{*}{\textbf{Tool}} & \multicolumn{6}{c}{\textbf{Vulnerability}} \\ \cline{2-7}
            % Integer Overflow, Integer Underflow, TOD, Stack Size Limit, Timesamp Dependency, Reentrancy
            & 1 & 2 & 3 & 4 & 5 & 6 \\
            \hline
            ContractWard & \ding{51} & \ding{51} & \ding{51} & \ding{51} & \ding{51} & \ding{51} \\
            ESCORT & & & & & & \\
            Zeus & \ding{51} & \ding{51} & \ding{51} &  & \ding{51} & \ding{51} \\
            \textsc{Oyente} & \ding{51} & \ding{51} &  & \ding{51} & \ding{51} & \ding{51} \\
            Maian\tnote{1} & \ding{55} & \ding{55} & \ding{55} & \ding{55} & \ding{55} & \ding{55} \\
            Manticore\tnote{2} & - & - & - & - & - & - \\
            Mythril & \ding{51} & \ding{51} & \ding{51} & \ding{51} & \ding{51} & \ding{51} \\
            Dedaub & ? & ? & ? & ? & ? & \ding{51} \\
            Securify & \ding{55} & \ding{55} & \ding{51} & \ding{55} & ? & \ding{51} \\
            Vandal & \ding{55} & \ding{55} & \ding{55} & \ding{55} & \ding{55} & \ding{51} \\
            Towards Sequential\tnote{3} & \ding{55} & \ding{55} & \ding{55} & \ding{55} & \ding{55} & \ding{55} \\
            NLP-inspried\tnote{4} & \ding{55} & \ding{55} & \ding{55} & \ding{55} & \ding{55} & \ding{55} \\
            Color-inspriedtnote{5} & \ding{51} & \ding{51} & \ding{51} & \ding{51} & \ding{51} & \ding{51} \\
            Graph NN-based & \ding{55} & \ding{55} & \ding{55} & \ding{51}\tnote{6} & \ding{51} & \ding{51} \\
            \bottomrule
        \end{tabularx}
        \begin{tablenotes}
            \item[1] Detects Greedy, suicidal and prodigal contracts.
            \item[2] Focuses on maximizing code coverage. Can be somewhat extended to detect more bugs/vulnerabilities.
            \item[3] Based on Maian.
            \item[4] Categories are Suicidal, Prodigal, Greedy, Normal Smart Contracts, and "Prodigal and Greedy".
            \item[5] Authors don't specifically list the detectable vulnerabilities.
            \item[6] Expressed as infinite loop vulnerabilities. This is also problematic for \gls{gas} consumption.
        \end{tablenotes}
    \end{threeparttable}
\end{table}


\subsection{Static Vulnerability Detection Methods}
Static vulnerability detection methods are performed without actually executing programs. The analysis is performed by examining the source code or \gls{bytecode} of the smart contract.

What is it the other tools have done different? Main differences, etc...
Include a view on WHICH vulnerabilities can be detected by which tools.\\

\todo{change to 1.2textwidth ?}
\begin{table}[htp]
    \newcolumntype{Y}{>{\centering\arraybackslash}X}
    \newcolumntype{R}{>{\raggedright\arraybackslash}X}
    \newcommand\T{\rule{0pt}{2.6ex}}       % Top strut or \bigstrut[t]
    \newcommand\B{\rule[-1.2ex]{0pt}{0pt}} % Bottom strut or \bigstrut[b]
    \def\arraystretch{1.5}
    \footnotesize
    \centering
    \caption{Existing static smart contract vulnerability detection tools.}
    \label{tab:static-tools}
    \begin{adjustbox}{center}
    \begin{threeparttable}
    \begin{tabularx}{1.2\textwidth}{cllRRR}
        \toprule
        \textbf{Refs.} & \textbf{Year} & \textbf{Name} & \textbf{Assistive technology} &  \textbf{Capability} & \textbf{Input\tnotex{tn:decompiled-sourcecode}} \\
        \hline        
        %\rule{0pt}{4ex}

        \multicolumn{6}{l}{\cellcolor{gray!10}{\textbf{Symbolic execution}}} \bigstrut \\
        \cite{luu2016making} & 2016 & \textsc{Oyente} & -- & Multi-class & Solidity*, \newline EVM bytecode \\
        \cite{albert2018ethir} & 2018 & \textsc{EthIR} & -- & General-purpose (depends on high-level verifier) & Solidity*, EVM bytecode \\
        \cite{albert2019safevm} & 2019 & \textsc{SAFEVM} & Symbolic model checking & General-purpose (depends on C verifier) & Solidity*, EVM bytecode \\
        \cite{zhou2018security} & 2018 & SASC & Topological analysis and syntax analysis & Multi-class & Solidity  \\
        %%% currently  here...
        \cite{mueller2018mythril} & 2018 & Mythril & Taint analysis and symbolic model checking & Multi-class & EVM bytecode \\
        \cite{zhang2019mpro} & 2018 & MPro & Taint analysis, symbolic model checking and data-flow analysis & Multi-class & EVM bytecode \\
        \cite{nikolic2018finding} & 2018 & Maian & Concrete validation & Multi-class & Solidity, \newline EVM bytecode \\
        \cite{tsankov2018securify} & 2018 & \textsc{Securify} & Abstract interpretation & Binary decision & Solidity*, EVM bytecode \\
        \cite{akca2019solanalyser} & 2019 & SolAnalyser & Code instrumentation and execution trace analysis & Multi-class & Solidity \\
        \cite{mossberg2019manticore} & 2019 & Manticore & -- & & EVM bytecode \\
        \cite{chien2020ra} & 2020 & RA & -- & Reentrancy & EVM bytecode \\
        
        \multicolumn{6}{l}{\cellcolor{gray!10}{\textbf{Syntax analysis}}} \bigstrut \\
        \cite{tikhomirov2018smartcheck} & \citeyear{tikhomirov2018smartcheck} & SmartCheck & Topological analysis & Multi-class & Solidity \\
        \cite{lu2019neucheck} & \citeyear{lu2019neucheck} & NeuCheck & -- & Multi-class & Solidity \\
        \cite{ma2020rejection} & \citeyear{ma2020rejection} & ReJection & -- & Reentrancy & Solidity \\
        
        \multicolumn{6}{l}{\cellcolor{gray!10}{\textbf{Abstract interpretation}}} \\
        \cite{kalra2018zeus} & 2018 & Zeus & Symbolic model checking & & Source code \\
        \cite{brent2018vandal} & 2018 & Vandal & Logic-driven analysis & Multi-class & Bytecode \\
        \cite{grech2018madmax} & 2018 & MadMax & Decompilation & Multi-class gas-related & EVM bytecode \\
        
        \multicolumn{6}{l}{\cellcolor{gray!10}{\textbf{Data Flow Analysis}}} \\
        \cite{feist2019slither} & 2019 & Slither & Taint analysis & Multi-class & Solidity \\
        \cite{ye2020clairvoyance} & 2020 & \textsc{Clairvoyance} & Taint analysis & Reentrancy & Solidity \\
        \cite{ali2021sescon} & 2020 & SESCon & Taint analysis and Syntax analysis & Multi-class & Solidity \\
        \bottomrule
    \end{tabularx}
    \begin{tablenotes}
        \item[a] \label{tn:decompiled-sourcecode} "*" means the source code is compiled down to bytecode.
    \end{tablenotes}
    \end{threeparttable}
\end{adjustbox}
\end{table}



\subsubsection{Symbolic Execution}
Symbolic execution is a ...

\paragraph{\textsc{Oyente}}
\textsc{Oyente} is one of the earliest Ethereum \acrshort{sc} vulnerability detection tool, developed by \textcite{oyente2016making} in \citeyear{oyente2016making}. The tool consists of four main components, named CFGBuilder, Explorer, CoreAnalysis, and Validator. The CFGBuilder component builds a \acrfull{cfg} of a smart contract. The Explorer component is a symbolic execution engine that explores the \acrshort{cfg}, using the \gls{z3} constraint solver for determining if a branch condition is either provably true or provably false along the current path. The CoreAnalysis component analyzes the explored CFG to detect vulnerabilities. The Validator component is finally used for eliminating false positives. \textsc{Oyente} uses EVM bytecode as its input. \textsc{Oyente} has paved the way for a lot of subsequent research. It is able to detect Call Stack Risk, Reentrancy Risk, Transaction Order Risk and Timestamp Risk.


\paragraph{\textsc{EthIR}}
\textcite{albert2018ethir} analyzes EVM bytecode based on the rule-based representations of \acrshort{cfg} produced by an improved version of \textsc{Oyente} \cite{oyente2016making}. The improvement primarily consist of including all possible jump addresses, whereas originally \textsc{Oyente} only stores the last jump address. This allows \textsc{EthIR} to produce a complete \acrshort{cfg}, containing both control-flow and data-flow information of the \acrshort{sc} EVM bytecode. From this, \textsc{EthIR} generates guarded rules for checking for conditional and unconditional jump instructions. This enables the application of (existing) high-level analyses to infer properties of the EVM code. \textcite{albert2018ethir} uses the high-level static analyzer SACO (Static Analyzer for Concurrent Objects) for checking conditional and unconditional jump instructions.

\paragraph{SAFEVM}
SAFEVM is an verification tool for Ethereum smart contracts that makes use of existing verification engines for C programs. \textcite{albert2019safevm} uses \textsc{Oyente} and \textsc{EthIR} in order to produce a rule-based representation of EVM bytecode or Solidity. This is then converted into a special C program. Existing analysis tools are then used to verify the security of the converted C program, and a report with the verification results is outputted.

\paragraph{\textsc{SASC}}
SASC \cite{zhou2018security} analyzes Ethereum \acrshortpl{sc} written in Solidity, and is able to detect the same logical vulnerabilities as that of \textsc{\textsc{Oyente}}. SASC primarily makes use of symbolic execution in order to detect vulnerabilities. However, the tool also makes use of syntax analysis, combined with topological analysis in order to locate a detected risk to a specific function.

\paragraph{SolAnalyser}
\todo{Is this symbolic execution, or trace analysis?}
SolAnalyser purposed by \textcite{akca2019solanalyser} uses code instrumentation and execution trace analysis in order to detect vulnerabilities in Solidity \acrshortpl{sc}. The authors proposes a fully automated pipeline for detecting vulnerabilities, as well as evaluating the tool with the help of creating a \acrshort{sc} mutation tool. 

\paragraph{Mythril}
Mythril, developed by \textcite{mueller2018mythril} is a command line tool, combining symbolic execution, with taint analysis and \acrshort{smt}. Mythril takes in EVM bytecode as input. In addition, Mythril also provides interfaces to allow for developers to write custom vulnerability detection logic. In order to cover the situation where a contract is called upon multiple times, Mythril simulates this through conducting multiple symbolic executions (two by default). 

\paragraph{MPro}
MPro by \textcite{zhang2019mpro} is a fully automated and scalable security scanning tool for Ethereum \acrshort{sc}. MPro combines the existing tools Mythril \cite{mueller2018mythril} and Slither \cite{feist2019slither}, leveraging both static and symbolic analysis to prune unnecessary execution paths and achieve \(n\) times efficiency increase than that of Mythril.

\paragraph{\textsc{Maian}}
\textsc{Maian} \cite{nikolic2018finding} is a symbolic execution tool for specifying and inferring trace vulnerabilities. \textcite{nikolic2018finding} points out that most existing tools ignore problems related to calling a contract multiple times. Contracts containing trace vulnerabilities could: lock funds indefinitely; allow for transfer founds to any address; be killed by anyone. Based on these attributes, \textsc{Maian} marks vulnerable contracts in three categories, greedy, prodigal, and suicidal. \textsc{Maian} takes EVM bytecode as input. Along with user-defined analysis targets, this allows for confirming the presence of a trace vulnerability.

\paragraph{\textsc{Securify}}
\textsc{Securify}\cite{tsankov2018securify} is a security analysis tool for Ethereum \acrshort{sc} that combines abstract interpretation with symbolic execution. Thee tool automatically classifies behaviors of a contract into three categories, compliance (matched by compliance properties), violation (matched by violation properties), and warning (matched by neither). \textsc{Securify} takes in EVM bytecode as input, along with a security model defined with a new domain-specific language. The use of a domain-specific language, enables users to express new vulnerability patterns as they emerge.

\paragraph{Manticore}
\todo{Investigate the effort neeeded to implement an other execution environment.}
Manticore \cite{mossberg2019manticore} is a flexible security analysis tool. It is based on symbolic execution and satisfiability modulo theories. It provides comprehensive API access, allowing the user to build custom symbolic execution-based tools. Further, Manticore's symbolic engine logic is decoupled from the details of a particular execution environment. This allows for support of various execution environments, such as both traditional environments(e.g., x86, ARM, and WASM), as well as Ethereum.

\paragraph{RA} 
RA by \textcite{chien2020ra} uses symbolic execution in order to detect re-entrancy vulnerabilities. The authors identifies that existing literature only report only program behavior via CFGs obtained within a single contract. Hence, RA focuses on analyzing re-entrancy attacks including inter-contract behavior. RA can analyze the vulnerabilities precisely, without false positives and false negatives.

\subsubsection{Syntactical analysis}
Syntactical analysis is a method to analyze computer programs by parsing the source code into a tree structure. This tree is then analyzed for its relation of each component.???

\paragraph{SmartCheck}
SmartCheck is an extensible analysis tool by \textcite{tikhomirov2018smartcheck} based on syntax analysis. SmartCheck takes Solidity source code as input and translates it into an XML parse tree as an \acrshort{ir}. This \acrshort{ir} is then checked against XPath patterns in order to detect coding issues. The authors classifies Solidity code issues into four categories, Security, Functional, Operational and Developmental. For example, SmartCheck is able to detect Solidity specific coding issues such as style guide violations, as well as the more common blockchain security vulnerabilities like Reentrancy problems. \todo{Findsomee way to formulate this...}

\paragraph{NeuCheck}
\textcite{lu2019neucheck} introduces NeuCheck, a cross-platform \acrshort{sc} syntax analysis tool for Ethereum. NeuCheck generates a syntax tree from Solidity source code, and generates an XML-based \acrshort{ir}. The open-source tool dom4j \footnote{\url{https://dom4j.github.io}} is then leveraged for parsing this tree and completing the analysis.

\paragraph{ReJection}
\textcite{ma2020rejection} purpose a method for detecting \acrshort{sc} reentrancy vulnerability detection based on analysis of \acrshortpl{ast}. The analysis conducted by ReJection is comprised of four steps. An \acrshort{ast} is generated from Solidity source code with the \acrshort{sc} compiler solc \footnote{\url{https://github.com/ethereum/solidity}}. This \acrshort{ast} is then pruned for redundant information. ReJection then traverses the \acrshort{ast}, analyzing and recording key information related to conditions of a reentrancy vulnerability. Finally, the tool decides whether there actually exists a reentrancy vulnerability,  depending on some determination rules summarized by the authors.


\subsubsection{Abstract interpretation}
Abstract interpretation is a method to analyze computer programs by interpreting the source code as a set of logical expressions. This set of logical expressions is then analyzed for its relation of each component. \todo{Rewrite this info.}

\paragraph{Zeus}
Zeus purposed by \textcite{kalra2018zeus} combines both abstract interpretation, symbolic model checking and constrained horn clauses. Model checking is verification method where a a system is modeled into a finite state machine. This is then used for verifying whether the system meets certain criteria. Zeus takes \Gls{solidity} \acrshort{sc} code as input, and translates it into an low-level \acrshort{ir} called \gls{llvmir}. \gls{llvm} is a compiler toolchain, that supports a large ecosystem of code analysis tools. Along with the \gls{llvm} code, Zeus also requires a user to provide a set of policies \todo{refs..} that are used in order to .... Finally, existing \gls{llvm} verification based tools are used on the constrained horn clauses to identify vulnerabilities.
\todo{include gray litterature - Zeus!!!}

\paragraph{MadMax}
MadMax is a gas-focused vulnerability detection tool by \textcite{grech2018madmax}. The authors creates a pipeline consisting of a control flow analysis based decompiler that disassembles EVM bytecode into a structured low-level \acrshort{ir}. This is then analyzed in DataLog \cite{datalog} by representing the \acrshort{ir} as DataLog \cite{datalog} facts. Along with data flow analysis along with context-sensitive flow analysis and memory layout modeling, the authors are able to automatically detect out-of-gas vulnerabilities.

\subsubsection{Data Flow Analysis}
Data flow analysis is a method to analyze computer programs by analyzing the flow of data through the source code. Often taint analysis... \todo{Rewrite this info.} Can analyze large programs, compared to, for example, symbolic execution.

\paragraph{Slither}
Slither \cite{feist2019slither} is a highly scalable static analysis tool which analyzes a smart contract source code at the intermediate representation SlithIR level. The \acrshort{ir} is constructed on the basis of a \acrlong{cfg}. Slither then applies both data-flow analysis and taint analysis techniques in order to detect vulnerabilities.

\paragraph{\textsc{Clairvoyance}}
\textsc{Clairvoyance} presents a static reentrancy detection approach \cite{ye2020clairvoyance}. The tool models cross-function and cross-contract behaviors, in order to enable a more sound analysis than Slither \cite{feist2019slither}, \textsc{Oyente} \cite{oyente2016making} and \textsc{Securify} \cite{tsankov2018securify}. \textsc{Clairvoyance} applies cross-contract static taint analysis to find reentrancy candidates, then integrates path protective techniques to refine the results. The authors claim that the tool significantly outperforms the three static tools in terms of precision and accuracy.

\paragraph{SESCon}
\textcite{ali2021sescon} presents a solution to detect \acrshort{sc} vulnerabilities through static analysis. SESCon is based on XPath and taint analysis. The tool first generates a AST based on Solidity code, and applies XPath queries in order to find simple vulnerability patterns. Then, a deeper analysis is conducted based on taint analysis. For this analysis, to generate vulnerability patterns, the authors extract state variables, local variables, control flow, graph dependency of functions, and payable and non-payable functions. \textcite{ali2021sescon} claims that SESCon outperforms other analyzers and can accurately detect up to 90\% of known vulnerability patterns.

Conclusion...
Symbolic execution is the most popular vulnerability detection method. It also seem that it is the most reliable method. Most mature.

\subsection{Formal Verification}
Formal Verification is a method to mathematically verify the correctness of a program. \todo{Rewisit this info.}

\subsection{Dynamic Vulnerability Detection Methods}
Dynamic program analysis is a form of analysis performed by executing programs on a real or virtual processor. This is in contrast to static program analysis. In order to detect vulnerabilities, the program is monitored during execution. However, in order to be effective, sufficient inputs needs to be provided/tested.

\begin{table}[htp]
    \newcolumntype{Y}{>{\centering\arraybackslash}X}
    \def\arraystretch{1.5}
    \small
    \centering
    \caption{Existing dynamic smart contract vulnerability detection tools.}
    \label{tab:dynamic-tools}
    \begin{tabularx}{\textwidth}{cll*{2}{X}}
        \toprule
        \textbf{Method} & \textbf{Name} &  \textbf{Assistive technology} &  \textbf{Capability} & \textbf{Input}\\ 
        \midrule
        \multirow{6}{*}{\rotatebox[origin=c]{90}{????}} & Dedaub & Flow and loop analysis & Gas-focused vulnerability & Sources code\\
        & ??  & ?? & ?? & ??\\
        & ??  & ?? & ?? & ??\\
        & ??  & ?? & ?? & ??\\
        & ??  & ?? & ?? & ??\\
        & ??  & ?? & ?? & ??\\
        \addlinespace[0.25cm]
        \midrule
        \addlinespace[0.25cm]
        \multirow{6}{*}{\rotatebox[origin=c]{90}{Fuzzing}} & ?? & ??  & ?? & ???\\
        & ??  & ?? & ?? & ??\\
        & ??  & ?? & ?? & ??\\
        & ??  & ?? & ?? & ??\\
        & ??  & ?? & ?? & ??\\
        & ??  & ?? & ?? & ??\\
        \bottomrule
    \end{tabularx}
\end{table}

\subsubsection{Fuzzing}
MythX
ReGuard (Reentrancy)
ContractFuzzer (ABI specifications)
Echidna
ILF

\subsubsection{Validation}
ContractLarva (runtime verification)
Maian ( "combines symbolic analysis and concrete validation to inspect the smart contract’s bytecode. In concrete validation, the contract is executed on a fork of Ethereum for tracing and vali- dation.")
Sereum 


\subsection{Machine Learning for Vulnerability Detection}
"Several works have attempted to perform automated contract scan- ning using machine learning techniques. We discuss their working mechanisms and limitations below."

\begin{table}[htp]
    \newcolumntype{Y}{>{\centering\arraybackslash}X}
    \def\arraystretch{1.5}
    \small
    \centering
    \caption{Existing ML-based smart contract vulnerability detection tools.}
    \label{tab:ml-tools}
    \begin{tabularx}{\textwidth}{lX*{2}{l}}
        \toprule
        \textbf{Name} & \textbf{Method} & \textbf{Capability} & \textbf{Input}\\ 
        \midrule
        ContractWard & Bigram model & Binary decision & Opcode\\
        ESCORT & LSTM + transfer learning & Multi-label & Bytecode\\
        Towards Sequential & LSTM & Binary decision & Opcode\\
        NLP-inspried \cite{gogineni2020multiclass} & AWD-LSTM & Multi-class & Opcode\\
        Color-inspried \cite{huang2018hunting} & CNN & Multi-label & Bytecode\\
        Graph NN-based \cite{zhuang2020smart} & GNN & Multi-class & Source code\\
        \bottomrule
    \end{tabularx}
\end{table}

\subsubsection{Long Short-Term Memory}

\subsubsection{Average Stochastic Gradient Descent Weighted Dropped LSTM}

\subsubsection{Convolutional Neural Network}

\subsubsection{Graph Neural Network}

\subsubsection{AWD-LSTM based}

\todo{Determine categoory of ML-based tools.}
\todo{Use multi class or binary decision categories?}
\todo{Use the input as sections?, Eg. AST, bytecode, source code, llvm, etc.}


\subsubsection{ContractWard}
ContractWard \cite{wang2021contractward} implements a smart contract vulnerability detection tool based on machine learning. It is a state-of-the-art tool for detecting smart contract vulnerabilities. It is a multi-label classifier that can detect multiple vulnerabilities. The method is based on a bigram model. The input is the bytecode of the smart contract. The output is a binary decision. The decision is 1 if the contract is vulnerable, 0 otherwise.

Models for Ethereum Smart Contracts Uses XGBoost as multi label classifier with SMOTETomke as sampling method. ses simplified smar contract opcodes as input. the static opcodes represent static featturesof contracts. the tool is appropriate for rapid batch detection of vulnerabilities in smart contracts, with an average detection speed of 4 seconds per contract. Reliable with Micro-F1 and Macro-F1 over 96\%. Only operates on opcodes as input.
simplified smart contract opcodes are extracted from the bytecode of smart contracts.

\subsubsection{ESCORT}
ESCORT provides a long short-term memory machine learning model in order to detect smart contract vulnerabilities. ContractScraper is used to extract the bytecode of the smart contract. The model is based on a long short-term memory (LSTM) network. The model is trained on the Ethereum blockchain. The model is able to detect multiple vulnerabilities. The model is capable of detecting the following vulnerabilities:

"ESCORT, the first Deep Neural Network (DNN)-based vulnerability detection framework for Ethereum smart contracts that supports lightweight transfer learning on unseen security vulnerabilities, thus is exten- sible and generalizable"












\section{Research Question 2: What is the current research on cross-chain \acrlong{sc} vulnerability detection?}

"Cross-chain vulnerability detection is a method for detecting vulnerabilities in smart contract code across multiple blockchains. Little efforts have been made to develop a cross-chain vulnerability detection framework. We discuss the challenges and opportunities of cross-chain vulnerability detection."


\textcite{kalra2018zeus} provides a tool called Zeus. Zeus translates the \Gls{solidity} \acrshort{sc} language into LLVM-IR language. \gls{llvm} is a compiler toolchain, that supports a large ecosystem of code analysis tools. However, the \gls{llvmir} is very is an \acrshort{ir} that  that can be used to detect vulnerabilities in the \acrshortpl{sc} language.

\textcite{lewispye2021general} conducts a systematic literature mapping identifying A General Framework for the Security Analysis of Blockchain Protocols

Besides the articles listed above, to my greatest extent, i have not been able to find any other research directly targeting cross-chain \acrlong{sc} vulnerability detection. However, there are some interesting solutions that demonstrates some cross-chain support.

\todo{Zeus: Emphasize on the need for policies and that it is a prototype implementation.} The most promising tool is Zeus by \textcite{kalra2018zeus} that allows for cross-chain compatibility through the use of \gls{llvm}. By using \gls{llvm}, any \acrshort{sc} language can be translated into the \gls{llvm} language. This is also the only existing tool that also demonstrates cross-chain support through a prototypal mock implementation for Hyperledger Fabric \cite{hyperledger-fabric}. 

Another solution is the \acrshort{sc} language \textsc{Scilla} by \textcite{sergey2018scilla}. This is supposed to be an type of intermediate language based on communicating automata. However, there are no automatic translation tools for converting another language into \textsc{Scilla}. Other similar solutions include converting \gls{solidity} into \gls{f-star}; a general-purpose functional programming language with effects aimed at program verification \cite{f-star}.

\section{Research Question 3: How to make \acrlong{sc} vulnerability detecting possible cross-chain?}

Draft:
Begin with using ML.. Then discuss existing solutions for AST analysis cross languages. 
Present research about cross language analysis. AST solutions, simplifications etc.

\textcite{matsumura2021vulnerabilities} suggest \acrshortpl{ml} for automatic vulnerability detection as future work. This because it is a promising vulnerability detection technique for traditional software, it doesn’t rely heavy on human-defined rules and has obtained competitive results.

for \acrshortpl{sc} vulnerability detection. This because \acrshortpl{ml} has been shown to be a promising vulnerability detection technique 

since it is a promising vulnerability detection technique even for traditional software [7,15], does not rely heavily on rules defined by human experts and has obtained competitive results; research proposing solutions involving dynamic analysis or software testing, seeking to deal with the limitations of the execution environment.
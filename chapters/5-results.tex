\chapter{Research results}
\label{chap:results}
This chapter presents the results of this \acrfull{slr}. Firstly, a descriptive analysis of the selected literature is presented. Following are the results for each of the research questions defined in \cref{sec:research-questions}.

\section{Descriptive analysis}
This study analyzes a total of ?? research papers, published between 2018 and 2021. No publications earlier than 2018 were available. From then on, the number of publications has drastically increased. An distribution of selected literature type ordered by year is illustrated in \cref{fig:literature-types}. It shows an upwards trend in term of publications. It is also to be noted that the majority of the publications are conference proceedings. This is to be expected, as the field of smart contract security is a relative new field.

\newcounter{groupcount}
\pgfplotsset{
    draw group line/.style n args={5}{
        after end axis/.append code={
            \setcounter{groupcount}{0}
            \pgfplotstableforeachcolumnelement{#1}\of\datatable\as\cell{%
                \def\temp{#2}
                \ifx\temp\cell
                    \ifnum\thegroupcount=0
                        \stepcounter{groupcount}
                        \pgfplotstablegetelem{\pgfplotstablerow}{[index]0}\of\datatable
                        \coordinate [yshift=#4] (startgroup) at (axis cs:\pgfplotsretval,0);
                    \else
                        \pgfplotstablegetelem{\pgfplotstablerow}{[index]0}\of\datatable
                        \coordinate [yshift=#4] (endgroup) at (axis cs:\pgfplotsretval,0);
                    \fi
                \else
                    \ifnum\thegroupcount=1
                        \setcounter{groupcount}{0}
                        \draw [
                            shorten >=-#5,
                            shorten <=-#5
                        ] (startgroup) -- node [anchor=base, yshift=0.5ex] {#3} (endgroup);
                        %] (startgroup) -- node [anchor=north] {#3} (endgroup);
                    \fi
                \fi
            }
            \ifnum\thegroupcount=1
                        \setcounter{groupcount}{0}
                        \draw [
                            shorten >=-#5,
                            shorten <=-#5
                        ] (startgroup) -- node [anchor=base, yshift=0.5ex] {#3} (endgroup);
                        %] (startgroup) -- node [anchor=north] {#3} (endgroup);
            \fi
        }
    }
}

\begin{figure}[htp]
    \centering
    \begin{tikzpicture}
        \pgfplotstableread[col sep = comma]{data/publication-year-type.csv}\datatable
        \begin{axis}[
            width=\textwidth,
            height=8cm,
            ymin=0,
            %ymax=23,
            %ylabel={Percentagem},
            xtick=data,
            xticklabels from table = {\datatable}{Document Type},
            xticklabel style={rotate=90,xshift=-5ex,anchor=mid east},
            ymajorgrids,
            draw group line={Publication Year}{2018}{2018}{-4ex}{7pt},
            draw group line={Publication Year}{2019}{2019}{-4ex}{7pt},
            draw group line={Publication Year}{2020}{2020}{-4ex}{7pt},
            draw group line={Publication Year}{2021}{2021}{-4ex}{7pt},
            ]
            \addplot [ybar,draw = blue,fill=blue!50, nodes near coords] table 
                     [x expr=\coordindex,
                      y=count,
                      ] {\datatable};
         \end{axis}
    \end{tikzpicture}
    \caption{Distribution of selected literature type by year.}
    \label{fig:literature-types}
\end{figure}



\section{Research Question 1: What are the current approaches for \acrlong{sc} vulnerability detection?}


Many tools and methods for vulnerability detection have been developed over the recent years. These tools can be categorized in terms of their primary function. Primarily, they can be divided into three categories: Static Vulnerability Detection, Dynamic Vulnerability Detection, and Machine Learning based Vulnerability Detection.

\todo{Graphover distributtion of tools of type... symbolic, ml, static, dynamic, etc...}
\todo{remove this table??}
The following table lists the tools and their respective categories.

\begin{table}[htp]
    \centering
    \caption{Vulnerabilities enumeration.}
    \label{tab:vulnerabilities-enumeration}
    \begin{tabular}{cllc}
        \toprule
        \# & \textbf{Vulnerability name} & \# & \textbf{Vulnerability name} \\
        \midrule
        1 & Integer Overflow & 4 & Stack Size Limit (deprecated) \\ 
        2 & Integer Underflow & 5 & Timestamp Dependency \\ 
        3 & Transaction-Ordering Dependence & 6 & Reentrancy \\
        
        \bottomrule
    \end{tabular}
\end{table}



\begin{table}[htp]
    \newcolumntype{Y}{>{\centering\arraybackslash}X}
    %\def\arraystretch{1.5}
    \centering
    \caption{Comparison of vulnerability types detectable by existing tools.}
    \label{tab:supported-vulnerabilities}
    \begin{threeparttable}
        \begin{tabularx}{\textwidth}{c*{6}{|Y}}
            \toprule
            \multirow{2}{*}{\textbf{Tool}} & \multicolumn{6}{c}{\textbf{Vulnerability}} \\ \cline{2-7}
            % Integer Overflow, Integer Underflow, TOD, Stack Size Limit, Timesamp Dependency, Reentrancy
            & 1 & 2 & 3 & 4 & 5 & 6 \\
            \hline
            ContractWard & \ding{51} & \ding{51} & \ding{51} & \ding{51} & \ding{51} & \ding{51} \\
            ESCORT & & & & & & \\
            Zeus & \ding{51} & \ding{51} & \ding{51} &  & \ding{51} & \ding{51} \\
            Oyente & \ding{51} & \ding{51} &  & \ding{51} & \ding{51} & \ding{51} \\
            Maian\tnote{1} & \ding{55} & \ding{55} & \ding{55} & \ding{55} & \ding{55} & \ding{55} \\
            Manticore\tnote{2} & - & - & - & - & - & - \\
            Mythril & \ding{51} & \ding{51} & \ding{51} & \ding{51} & \ding{51} & \ding{51} \\
            Dedaub & ? & ? & ? & ? & ? & \ding{51} \\
            Securify & \ding{55} & \ding{55} & \ding{51} & \ding{55} & ? & \ding{51} \\
            Vandal & \ding{55} & \ding{55} & \ding{55} & \ding{55} & \ding{55} & \ding{51} \\
            Towards Sequential\tnote{3} & \ding{55} & \ding{55} & \ding{55} & \ding{55} & \ding{55} & \ding{55} \\
            NLP-inspried\tnote{4} & \ding{55} & \ding{55} & \ding{55} & \ding{55} & \ding{55} & \ding{55} \\
            Color-inspriedtnote{5} & \ding{51} & \ding{51} & \ding{51} & \ding{51} & \ding{51} & \ding{51} \\
            Graph NN-based & \ding{55} & \ding{55} & \ding{55} & \ding{51}\tnote{6} & \ding{51} & \ding{51} \\
            \bottomrule
        \end{tabularx}
        \begin{tablenotes}
            \item[1] Detects Greedy, suicidal and prodigal contracts.
            \item[2] Focuses on maximizing code coverage. Can be somewhat extended to detect more bugs/vulnerabilities.
            \item[3] Based on Maian.
            \item[4] Categories are Suicidal, Prodigal, Greedy, Normal Smart Contracts, and "Prodigal and Greedy".
            \item[5] Authors don't specifically list the detectable vulnerabilities.
            \item[6] Expressed as infinite loop vulnerabilities. This is also problematic for \gls{gas} consumption.
        \end{tablenotes}
    \end{threeparttable}
\end{table}


\subsection{Static Vulnerability Detection Methods}
Static vulnerability detection methods are performed without actually executing programs. The analysis is performed by examining the source code or \gls{bytecode} of the smart contract.
\todo{determine if to use "Input" or "Level"}
\todo{change to 1.2 textwidth ?}
\begin{table}[htp]
    \newcolumntype{Y}{>{\centering\arraybackslash}X}
    \newcolumntype{R}{>{\raggedright\arraybackslash}X}
    \newcommand\T{\rule{0pt}{2.6ex}}       % Top strut or \bigstrut[t]
    \newcommand\B{\rule[-1.2ex]{0pt}{0pt}} % Bottom strut or \bigstrut[b]
    \def\arraystretch{1.5}
    \footnotesize
    \centering
    \caption{Existing static smart contract vulnerability detection tools.}
    \label{tab:static-tools}
    \begin{adjustbox}{center}
    \begin{tabularx}{1.2\textwidth}{cllRlR}
        \toprule
        \textbf{Refs.} & \textbf{Year} & \textbf{Name} & \textbf{Assistive technology} &  \textbf{Capability} & \textbf{Input} \\
        \hline        
        %\rule{0pt}{4ex}

        \multicolumn{6}{l}{\cellcolor{gray!10}{\textbf{Symbolic execution}}} \bigstrut \\
        \cite{luu2016making} & 2016 & \textsc{Oyente} & -- & Multi-class & Solidity, \newline EVM bytecode \\
        \cite{MISSING} & 2018 & \textsc{EthIR} & -- & ?? & Solidity, EVM bytecode \\
        \cite{zhou2018security} & 2018 & SASC & Topological analysis and syntax analysis & Multi-class & Solidity  \\
        \cite{akca2019solanalyser} & 2019 & SolAnalyser & Code instrumentation and execution trace analysis & Multi-class & Solidity \\
        %%% currently  here...
        \cite{MISSING} & 2018 & Mythril & Taint analysis and symbolic model checking & Multi-class & EVM bytecode \\
        \cite{zhang2019mpro} & 2018 & MPro & Taint analysis, symbolic model checking and data-flow analysis & Multi-class & EVM bytecode \\
        \cite{MISSING} & 2018 & Maian & Concrete validation & Multi-class & Solidity, \newline EVM bytecode \\
        \cite{MISSING} & 2018 & Securify & Abstract interpretation & Binary decision & EVM bytecode \\
        \cite{MISSING} & 2019 & Manticore & -- & & EVM bytecode \\
        \cite{chien2020ra} & 2020 & RA & -- & Reentrancy & EVM bytecode \\
        
        \multicolumn{6}{l}{\cellcolor{gray!10}{\textbf{Syntax analysis}}} \bigstrut \\
        \cite{tikhomirov2018smartcheck} & \citeyear{tikhomirov2018smartcheck} & SmartCheck & Topological analysis & Multi-class & Solidity \\
        \cite{lu2019neucheck} & \citeyear{lu2019neucheck} & NeuCheck & -- & Multi-class & Solidity \\
        
        \multicolumn{6}{l}{\cellcolor{gray!10}{\textbf{Abstract interpretation}}} \\
        \cite{kalra2018zeus} & 2018 & Zeus & Symbolic model checking & & Source code \\
        \cite{brent2018vandal} & 2018 & Vandal & Logic-driven analysis & Multi-class & Bytecode \\
        \cite{grech2018madmax} & 2018 & MadMax & Decompilation & Multi-class gas-related & EVM bytecode \\
        
        \multicolumn{6}{l}{\cellcolor{gray!10}{\textbf{Data Flow Analysis}}} \\
        \cite{MISSING} & 2019 & Slither & Taint analysis & ?? & Solidity \\
        \cite{ye2020clairvoyance} & 2020 & \textsc{Clairvoyance} & Taint analysis & Reentrancy & Solidity \\
        \cite{ali2021sescon} & 2020 & SESCon & Taint analysis and Syntax analysis & Multi-class & Solidity \\
        \bottomrule
    \end{tabularx}
\end{adjustbox}
\end{table}

\subsubsection{Symbolic Execution}
Symbolic execution is a ...

What is it the other tools have done different? Main differences, etc...
Include a view on WHICH vulnerabilities can be detected by which tools.\\\\

\paragraph{\textsc{Oyente}}
Oyente is one of the earliest Ethereum \acrshort{sc} vulnerability detection tool, developed by \textcite{oyente2016making} in \citeyear{oyente2016making}. The tool consists of four main components, named CFGBuilder, Explorer, CoreAnalysis, and Validator. The CFGBuilder component builds a \acrfull{cfg} of a smart contract. The Explorer component is a symbolic execution engine that explores the \acrshort{cfg}, using the \gls{z3} constraint solver for determining if a branch condition is either provably true or provably false along the current path. The CoreAnalysis component analyzes the explored CFG to detect vulnerabilities. The Validator component is finally used for eliminating false positives. Oyente uses bytecode as its input. It has some problems bla bla bla, but Oyente has paved the way for a lot of subsequent research. It is able to detect Call Stack Risk, Reentrancy Risk, Transaction Order Risk and Timestamp Risk.

\paragraph{\textsc{SASC}}
SASC \cite{zhou2018security} analyzes Ethereum \acrshortpl{sc} written in Solidity, and is able to detect the same logical vulnerabilities as that of \textsc{Oyente}. SASC primarily makes use of symbolic execution in order to detect vulnerabilities. However, the tool also makes use of syntax analysis, combined with topological analysis in order to locate a detected risk to a specific function.

\paragraph{\textsc{SolAnalyser}}
\todo{Is this symbolic execution, or trace analysis?}
SolAnalyser purposed by \textcite{akca2019solanalyser} uses code instrumentation and execution trace analysis in order to detect vulnerabilities in Solidity \acrshortpl{sc}. The authors proposes a fully automated pipeline for detecting vulnerabilities, as well as evaluating the tool with the help of creating a \acrshort{sc} mutation tool. 

\subsubsection{Syntactical analysis}
Syntactical analysis is a method to analyze computer programs by parsing the source code into a tree structure. This tree is then analyzed for its relation of each component.???

\paragraph{SmartCheck}
SmartCheck is an extensible analysis tool by \textcite{tikhomirov2018smartcheck} based on syntax analysis. SmartCheck takes Solidity source code as input and translates it into an XML parse tree as an \acrshort{ir}. This \acrshort{ir} is then checked against XPath patterns in order to detect coding issues. The authors classifies Solidity code issues into four categories, Security, Functional, Operational and Developmental. For example, SmartCheck is able to detect Solidity specific coding issues such as style guide violations, as well as the more common blockchain security vulnerabilities like Reentrancy problems. \todo{Findsomee way to formulate this...}

\paragraph{NeuCheck}
\textcite{lu2019neucheck} introduces NeuCheck, a cross-platform \acrshort{sc} syntax analysis tool for Ethereum. NeuCheck generates a syntax tree from Solidity source code, and generates an XML-based \acrshort{ir}. The open-source tool dom4j \cite{dom4j} is then leveraged for parsing this tree and completing the analysis.


\paragraph{Mythril}
Mythril \textcite{MISSING} is 

\paragraph{MPro}
MPro by \textcite{zhang2019mpro} is a fully automated and scalable security scanning tool for Ethereum \acrshort{sc}. MPro combines the existing tools Mythril \cite{MISSING} and Slither \cite{MISSING}, leveraging both static and symbolic analysis to prune unnecessary execution paths and achieve \(n\) times efficiency increase than that of Mythril.

\paragraph{RA} 
RA by \textcite{chien2020ra} uses symbolic execution in order to detect re-entrancy vulnerabilities. The authors identifies that existing literature only report only program behavior via CFGs obtained within a single contract. Hence, RA focuses on analyzing re-entrancy attacks including inter-contract behavior. RA can analyze the vulnerabilities precisely, without false positives and false negatives.

\paragraph{\textsc{Maian}}
Maian \textcite{nikolic2018finding} is

\subsubsection{Abstract interpretation}
Abstract interpretation is a method to analyze computer programs by interpreting the source code as a set of logical expressions. This set of logical expressions is then analyzed for its relation of each component. \todo{Rewrite this info.}

\paragraph{MadMax}
MadMax is a gas-focused vulnerability detection tool by \textcite{grech2018madmax}. The authors creates a pipeline consisting of a control flow analysis based decompiler that disassembles EVM bytecode into a structured low-level \acrshort{ir}. This is then analyzed in DataLog \cite{datalog} by representing the \acrshort{ir} as DataLog \cite{datalog} facts. Along with data flow analysis along with context-sensitive flow analysis and memory layout modeling, the authors are able to automatically detect out-of-gas vulnerabilities.

\paragraph{Zeus} purposed by \textcite{kalra2018zeus} combines both abstract interpretation, symbolic model checking and constrained horn clauses. Model checking is verification method where a a system is modeled into a finite state machine. This is then used for verifying whether the system meets certain criteria. Zeus takes \Gls{solidity} \acrshort{sc} code as input, and translates it into an low-level \acrshort{ir} called \gls{llvmir}. \gls{llvm} is a compiler toolchain, that supports a large ecosystem of code analysis tools. Along with the \gls{llvm} code, Zeus also requires a user to provide a set of policies \todo{refs..} that are used in order to .... Finally, existing \gls{llvm} verification based tools are used on the constrained horn clauses to identify vulnerabilities.
\todo{include gray litterature - Zeus!!!}

\subsubsection{Data Flow Analysis}
Data flow analysis is a method to analyze computer programs by analyzing the flow of data through the source code. Often taint analysis... \todo{Rewrite this info.}

\paragraph{Slither}
Slither \cite{MISSING} is a highly scalable static analysis tool which analyzes a smart contract source code at the intermediate representation SlithIR level

\paragraph{\textsc{Clairvoyance}}
\textsc{Clairvoyance} presents a static reentrancy detection approach \cite{ye2020clairvoyance}. The tool models cross-function and cross-contract behaviors, in order to enable a more sound analysis than Slither \cite{MISSING}, Oyente \cite{oyente2016making} and Securify \cite{tsankov2018securify}. \textsc{Clairvoyance} applies cross-contract static taint analysis to find reentrancy candidates, then integrates path protective techniques to refine the results. The authors claim that the tool significantly outperforms the three static tools in terms of precision and accuracy.

\paragraph{SESCon}
\textcite{ali2021sescon} presents a solution to detect \acrshort{sc} vulnerabilities through static analysis. SESCon is based on XPath and taint analysis. The tool first generates a AST based on Solidity code, and applies XPath queries in order to find simple vulnerability patterns. Then, a deeper analysis is conducted based on taint analysis. For this analysis, to generate vulnerability patterns, the authors extract state variables, local variables, control flow, graph dependency of functions, and payable and non-payable functions. \textcite{ali2021sescon} claims that SESCon outperforms other analyzers and can accurately detect up to 90\% of known vulnerability patterns.

Conclusion:
Symbolic execution is the most popular vulnerability detection method. It also seem that it is the most reliable method. Most mature.


\subsection{Formal Verification}
Formal Verification is a method to mathematically verify the correctness of a program. \todo{Rewisit this info.}


\subsection{Dynamic Vulnerability Detection Methods}
Dynamic program analysis is a form of analysis performed by executing programs on a real or virtual processor. This is in contrast to static program analysis. In order to detect vulnerabilities, the program is monitored during execution. However, in order to be effective, sufficient inputs needs to be provided/tested.

\begin{table}[htp]
    \newcolumntype{Y}{>{\centering\arraybackslash}X}
    \def\arraystretch{1.5}
    \small
    \centering
    \caption{Existing dynamic smart contract vulnerability detection tools.}
    \label{tab:dynamic-tools}
    \begin{tabularx}{\textwidth}{cll*{2}{X}}
        \toprule
        \textbf{Method} & \textbf{Name} &  \textbf{Assistive technology} &  \textbf{Capability} & \textbf{Input}\\ 
        \midrule
        \multirow{6}{*}{\rotatebox[origin=c]{90}{????}} & Dedaub & Flow and loop analysis & Gas-focused vulnerability & Sources code\\
        & ??  & ?? & ?? & ??\\
        & ??  & ?? & ?? & ??\\
        & ??  & ?? & ?? & ??\\
        & ??  & ?? & ?? & ??\\
        & ??  & ?? & ?? & ??\\
        \addlinespace[0.25cm]
        \midrule
        \addlinespace[0.25cm]
        \multirow{6}{*}{\rotatebox[origin=c]{90}{Fuzzing}} & ?? & ??  & ?? & ???\\
        & ??  & ?? & ?? & ??\\
        & ??  & ?? & ?? & ??\\
        & ??  & ?? & ?? & ??\\
        & ??  & ?? & ?? & ??\\
        & ??  & ?? & ?? & ??\\
        \bottomrule
    \end{tabularx}
\end{table}

\subsubsection{Fuzzing}
MythX
ReGuard (Reentrancy)
ContractFuzzer (ABI specifications)
Echidna
ILF

\subsubsection{Validation}
ContractLarva (runtime verification)
Maian ( "combines symbolic analysis and concrete validation to inspect the smart contract’s bytecode. In concrete validation, the contract is executed on a fork of Ethereum for tracing and vali- dation.")
Sereum 


\subsection{Machine Learning for Vulnerability Detection}
"Several works have attempted to perform automated contract scan- ning using machine learning techniques. We discuss their working mechanisms and limitations below."

\begin{table}[htp]
    \newcolumntype{Y}{>{\centering\arraybackslash}X}
    \def\arraystretch{1.5}
    \small
    \centering
    \caption{Existing ML-based smart contract vulnerability detection tools.}
    \label{tab:ml-tools}
    \begin{tabularx}{\textwidth}{lX*{2}{l}}
        \toprule
        \textbf{Name} & \textbf{Method} & \textbf{Capability} & \textbf{Input}\\ 
        \midrule
        ContractWard & Bigram model & Binary decision & Opcode\\
        ESCORT & LSTM + transfer learning & Multi-label & Bytecode\\
        Towards Sequential & LSTM & Binary decision & Opcode\\
        NLP-inspried \cite{gogineni2020multiclass} & AWD-LSTM & Multi-class & Opcode\\
        Color-inspried \cite{huang2018hunting} & CNN & Multi-label & Bytecode\\
        Graph NN-based \cite{zhuang2020smart} & GNN & Multi-class & Source code\\
        \bottomrule
    \end{tabularx}
\end{table}

\subsubsection{Long Short-Term Memory}

\subsubsection{Average Stochastic Gradient Descent Weighted Dropped LSTM}

\subsubsection{Convolutional Neural Network}

\subsubsection{Graph Neural Network}

\subsubsection{AWD-LSTM based}

\todo{Determine categoory of ML-based tools.}
\todo{Use multi class or binary decision categories?}
\todo{Use the input as sections?, Eg. AST, bytecode, source code, llvm, etc.}


\subsubsection{ContractWard}
ContractWard \cite{wang2021contractward} implements a smart contract vulnerability detection tool based on machine learning. It is a state-of-the-art tool for detecting smart contract vulnerabilities. It is a multi-label classifier that can detect multiple vulnerabilities. The method is based on a bigram model. The input is the bytecode of the smart contract. The output is a binary decision. The decision is 1 if the contract is vulnerable, 0 otherwise.

Models for Ethereum Smart Contracts Uses XGBoost as multi label classifier with SMOTETomke as sampling method. ses simplified smar contract opcodes as input. the static opcodes represent static featturesof contracts. the tool is appropriate for rapid batch detection of vulnerabilities in smart contracts, with an average detection speed of 4 seconds per contract. Reliable with Micro-F1 and Macro-F1 over 96\%. Only operates on opcodes as input.
simplified smart contract opcodes are extracted from the bytecode of smart contracts.

\subsubsection{ESCORT}
ESCORT provides a long short-term memory machine learning model in order to detect smart contract vulnerabilities. ContractScraper is used to extract the bytecode of the smart contract. The model is based on a long short-term memory (LSTM) network. The model is trained on the Ethereum blockchain. The model is able to detect multiple vulnerabilities. The model is capable of detecting the following vulnerabilities:

"ESCORT, the first Deep Neural Network (DNN)-based vulnerability detection framework for Ethereum smart contracts that supports lightweight transfer learning on unseen security vulnerabilities, thus is exten- sible and generalizable"












\section{Research Question 2: What is the current research on cross-chain \acrlong{sc} vulnerability detection?}

"Cross-chain vulnerability detection is a method for detecting vulnerabilities in smart contract code across multiple blockchains. Little efforts have been made to develop a cross-chain vulnerability detection framework. We discuss the challenges and opportunities of cross-chain vulnerability detection."


\textcite{kalra2018zeus} provides a tool called Zeus. Zeus translates the \Gls{solidity} \acrshort{sc} language into LLVM-IR language. \gls{llvm} is a compiler toolchain, that supports a large ecosystem of code analysis tools. However, the \gls{llvmir} is very is an \acrshort{ir} that  that can be used to detect vulnerabilities in the \acrshortpl{sc} language.

\textcite{lewispye2021general} conducts a systematic literature mapping identifying A General Framework for the Security Analysis of Blockchain Protocols

Besides the articles listed above, to my greatest extent, i have not been able to find any other research directly targeting cross-chain \acrlong{sc} vulnerability detection. However, there are some interesting solutions that demonstrates some cross-chain support.

\todo{Zeus: Emphasize on the need for policies and that it is a prototype implementation.} The most promising tool is Zeus by \textcite{kalra2018zeus} that allows for cross-chain compatibility through the use of \gls{llvm}. By using \gls{llvm}, any \acrshort{sc} language can be translated into the \gls{llvm} language. This is also the only existing tool that also demonstrates cross-chain support through a prototypal mock implementation for Hyperledger Fabric \cite{hyperledger-fabric}. 

Another solution is the \acrshort{sc} language \textsc{Scilla} by \textcite{sergey2018scilla}. This is supposed to be an type of intermediate language based on communicating automata. However, there are no automatic translation tools for converting another language into \textsc{Scilla}. Other similar solutions include converting \gls{solidity} into \gls{f-star}; a general-purpose functional programming language with effects aimed at program verification \cite{f-star}.

\section{Research Question 3: How to make \acrlong{sc} vulnerability detecting possible cross-chain?}

Draft:
Begin with using ML.. Then discuss existing solutions for AST analysis cross languages. 
Present research about cross language analysis. AST solutions, simplifications etc.

\textcite{matsumura2021vulnerabilities} suggest \acrshortpl{ml} for automatic vulnerability detection as future work. This because it is a promising vulnerability detection technique for traditional software, it doesn’t rely heavy on human-defined rules and has obtained competitive results.

for \acrshortpl{sc} vulnerability detection. This because \acrshortpl{ml} has been shown to be a promising vulnerability detection technique 

since it is a promising vulnerability detection technique even for traditional software [7,15], does not rely heavily on rules defined by human experts and has obtained competitive results; research proposing solutions involving dynamic analysis or software testing, seeking to deal with the limitations of the execution environment.